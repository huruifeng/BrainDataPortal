{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to BrainDataPortal Docs!","text":"<p>BrainDataPortal is a comprehensive platform for single-cell, spatial transcriptomics, and other omics data visualization and exploration.  This documentation will guide you through the installation and data preparation processes.</p>"},{"location":"#overview","title":"Overview","text":"<ul> <li>This is project designed for the brain multi-modal data visualization and exploration.</li> <li>The supported assays include: scRNAseq, scATACseq, Visium Spatial Transcriptomics, xQTL, GWAS.</li> <li>The backend is running on FastAPI and uvicorn.</li> <li>The frontend is built with React and Vite.</li> <li>The data is stored in SQLite3 and JSON files.</li> <li>Use zustand for state management, and Material UI for web page layout design</li> </ul>"},{"location":"#directory-structure","title":"Directory structure","text":"<pre><code>BrainDataPortal/\n|-- Backend/\n|   |-- main.py                         ## The main entry of the backend\n|   |-- db.py                           ## The database connection and management\n|   |-- settings.py                     ## The configuration of the backend\n|   |-- requirements.txt                ## The required libraries of the backend\n|   |-- funcs/                          ## This folder contains request handler functions of the backend\n|   |   |-- get_data.py                 ## The request handler functions for data\n|   |   |-- utils.py                    ## The utils functions\n|   |   `-- ...\n|   |-- models/                         ## This folder contains database models of the backend\n|   |   |-- dataset.py                  ## The dataset model/table\n|   |   `-- ...\n|   |-- routes/                         ## This folder contains routes endpoints of requests\n|   |   |-- api_routes.py                \n|   |   |-- qtl_routes.py\n|   |   |-- visium_routes.py\n|   |   `-- ...\n|   |-- SampleSheets/                   ## Upload sample sheets here when adding new datasets\n|   |   |-- Sample_snRNAseq.csv\n|   |   `-- ...\n|   |-- datasets/                       ## The datasets are stored here\n|   |   |-- dataset_1/\n|   |   |   |-- meta_cell.json\n|   |   |   |-- meta_sample.json\n|   |   |   |-- ...\n|   |   `-- ...\n|   |-- bdp_db.db                        ## The database file\n|   `-- ...\n|-- Frontend\n|   |-- index.html                      ## The entry page of the frontend\n|   |-- vite.config.js                  ## The vite configuration file\n|   |-- package.json                    ## The dependencies and dev/build settings of the frontend\n|   |-- env/                            ## The environment variables\n|   |   |-- .env                        ## The global environment variables\n|   |   |-- .env.development            ## The development environment variables\n|   |   `-- .env.production             ## The production environment variables\n|   |-- src/                            ## The source code of the frontend\n|   |   |-- App.jsx                     ## Define the routes of the frontend\n|   |   |-- index.css                   ## The global styles of the frontend\n|   |   |-- main.jsx                   ## The entry file of the frontend\n|   |   |-- components/                 ## The components of the frontend\n|   |   |   `-- ...\n|   |   |-- pages/                      ## The pages of the frontend\n|   |   |   `-- ...\n|   |   |-- utils/                      ## The fucntional utils\n|   |   |   `-- ...\n|   |   |-- store/                      ## The stores for state management\n|   |   |-- api/                        ## The api for data fetching\n|   |   `-- ...\n|   `-- ...\n`-- README.md\n</code></pre>"},{"location":"#video-demo","title":"Video demo","text":""},{"location":"#gene-view-umap","title":"Gene view UMAP","text":"Your browser does not support the video tag."},{"location":"#visiumst-view","title":"VisiumST view","text":"Your browser does not support the video tag.  <p>Get Started</p>"},{"location":"contribute/","title":"Make contributions","text":"<p>This App is open source and welcomes contributions from the community. </p> <p>If you have any questions or suggestions, please feel free to open an issue or submit a pull request.</p> <p>The repository is hosted on GitHub at huruifeng/BrainDataPortal.</p>"},{"location":"contribute/#make-a-pull-request","title":"Make a pull request","text":"<ol> <li>Fork the repository</li> <li>Create a new branch</li> <li>Make your changes</li> <li>Commit your changes</li> <li>Push your changes to your fork</li> <li>Create a pull request</li> <li>Wait for the maintainers to review your pull request</li> <li>Merge your pull request</li> <li>Update your fork</li> <li>Update your local repository</li> </ol>"},{"location":"demos/scripts/xqtl/","title":"Index","text":""},{"location":"demos/scripts/xqtl/#notes-on-dataset-preparation","title":"NOTES ON DATASET PREPARATION","text":"<p>Christopher Zhang, Ruifeng Hu</p>"},{"location":"demos/scripts/xqtl/#table-of-contents","title":"Table of Contents","text":""},{"location":"demos/scripts/xqtl/#1-introduction","title":"1. Introduction","text":""},{"location":"demos/scripts/xqtl/#2-data-requirements","title":"2. Data Requirements","text":""},{"location":"demos/scripts/xqtl/#3-data-organization","title":"3. Data Organization","text":""},{"location":"demos/scripts/xqtl/#4-design-reasoning","title":"4. Design Reasoning","text":""},{"location":"demos/scripts/xqtl/#5-scripts","title":"5. Scripts","text":""},{"location":"demos/scripts/xqtl/#1-introduction_1","title":"1 Introduction","text":"<p>This document describes the structure of the dataset used for eQTL   visualization, along with the reasoning behind these choices.</p> <p>The visualization has two views:   - Gene View: A gene track is displayed at the bottom showing the      selected gene in black and nearby significant genes in gray.[1]      Above it, scatter plots show SNPs associated with each celltype.   - SNP View: A SNP track is displayed at the bottom showing the      selected SNP in black and nearby significant SNPs in gray.[2] Above      it, scatter plots show genes associated with each celltype.</p> <p>In both views:   - The x-axis represents the genomic position (gene start and end or     SNP position).   - The y-axis represents \u2212log_{10}(p).   - Point color reflects the beta value, with red for positive and blue     for negative. The strongest colors correspond to the largest     magnitude of beta value; smaller beta values are grayer.</p>"},{"location":"demos/scripts/xqtl/#2-data-requirements_1","title":"2 Data Requirements","text":"<p>The visualization requires two types of data:</p> <p>QTL Data:   - Gene ID   - SNP ID   - p-value   - beta</p> <p>Annotation Data:   - Genes: chromosome, start position, end position, strand   - SNPs: chromosome, position</p>"},{"location":"demos/scripts/xqtl/#3-data-organization_1","title":"3 Data Organization","text":"<p>The dataset is organized into the following directory structure:</p> <pre><code>dataset/\n|-- celltype_mapping.json\n|-- celltypes\n|   |-- Astrocytes.parquet\n|   |-- ...\n|   `-- Pericytes.parquet\n|-- gene_jsons\n|   |-- A1BG.json\n|   |-- ...\n|   `-- A2M.json\n|-- gene_list.json\n|-- gene_locations\n|   |-- chr1.parquet\n|   |-- ...\n|   `-- chr22.parquet\n|-- snp_jsons\n|   |-- rs12345678.json\n|   |-- ...\n|   `-- rs7288382.json\n|-- snp_list.json\n`-- snp_locations\n    |-- chr1.parquet\n    |-- ...\n    `-- chr22.parquet\n</code></pre> <ul> <li><code>celltype_mapping.json</code>         Maps display names to filenames in <code>celltypes/'.</code>celltypes/`         Per-celltype Parquet files for QTL data (only including gene-SNP         pairs significant in at least one celltype[3]).</li> <li><code>gene_jsons/</code> and <code>snp_jsons/</code>         Individual JSON annotation files for each gene and SNP,         including their associated celltypes.</li> <li><code>gene_list.json</code> and <code>snp_list.json</code>         Lists of all genes and SNPs in the dataset.</li> <li><code>gene_locations/</code> and <code>snp_locations/</code>         Per-chromosome Parquet files containing annotation data.</li> </ul>"},{"location":"demos/scripts/xqtl/#4-design-reasoning_1","title":"4 Design Reasoning","text":"<p>Several choices were made to prioritize speed:</p> <p>Redundant Annotations         Each gene and SNP has its own JSON file for annotations to allow         fast access.   Precomputed Celltypes         Storing celltype information directly in annotation JSON files         speeds up loading times by querying and displaying only         celltypes containing significant data.   Bulk Annotations         <code>gene_locations/</code> and <code>snp_locations/</code> store annotation data in         bulk so nearby genes/SNPs in the chromosome can be quickly         loaded without opening a bunch of small files.   Filtering         By pre-filtering to only significant entries, we reduce the         amount of data that needs to be processed and plotted.   Parquet Format         Storing files in Parquet format allows for compression and         increases speed over text formats like CSV or TSV.</p> <p>Overall, we trade some disk space (especially individual annotation   files) for much faster loading times. In future versions, individual   annotation files may potentially be removed if speed is sufficient.</p>"},{"location":"demos/scripts/xqtl/#5-scripts_1","title":"5 Scripts","text":"<p>The dataset is constructed through six scripts:</p> <ol> <li> <p>Preprocessing</p> <ul> <li>This script should vary depending on the input data.</li> <li>Renames QTL data columns to `gene_id, snp_id, p_value,    beta_value'.</li> <li>Splits QTL data by celltype into `unfiltered_celltypes/'.</li> <li>Renames gene and SNP annotation columns to <code>gene_id,    position_start, position_end, strand' and</code>snp_id, position'.</li> <li>Splits gene and SNP annotation files by chromosome into    <code>gene_locations/</code> and <code>snp_locations/</code> (deduplicated).</li> </ul> </li> <li> <p>Filter by Significance</p> <ul> <li>Filters each celltype in `unfiltered_celltypes/' for entries with    p &gt; 0.01.</li> <li>Outputs filtered TSVs into `filtered_celltypes/'.</li> </ul> </li> <li> <p>Celltype Mapping</p> <ul> <li>Prompts user for display names that correspond to filenames in    `celltypes/'.</li> <li>Generates `celltype_mapping.json' accordingly.</li> </ul> </li> <li> <p>Global Significance Filtering</p> <ul> <li>Identifies gene-SNP pairs significant in at least one celltype    using `filtered_celltypes/'.</li> <li>Filters `unfiltered_celltypes/' accordingly.</li> <li>Outputs filtered TSVs into `celltypes/'.</li> </ul> </li> <li> <p>Generate Annotation JSONs</p> <ul> <li>Creates individual JSON files for each gene and SNP in    <code>gene_locations/</code> and <code>snp_locations/</code>.</li> <li>Includes list of celltypes in which each appears.</li> </ul> </li> <li> <p>Convert to Parquet</p> <ul> <li>Converts all necessary TSV files to Parquet format for final use.</li> </ul> </li> </ol> <p>Intermediate folders like <code>unfiltered_celltypes/</code> and   <code>filtered_celltypes/</code> are not automatically deleted; users can choose   to remove them if disk space is an issue.</p> <p>Footnotes</p> <p>[1] In the next release, this will be replaced with all nearby genes, with appropriate error handling if not present in the dataset.</p> <p>[2] In the next release, this will be replaced with GWAS data.</p> <p>[3] Entries are significant if \u2212log_{10}(p) &gt; 2, which is equivalent to p &lt; 0.01.</p>"},{"location":"development/","title":"Development guide","text":"<p>This is an open souce project, you can find the source code on GitHub.</p> <p>The home page can be customized to be fit for your own use case. </p> <p>You can also add new visualization views to the app. This is a more advanced topic and requires knowledge of React(JavaScript), FastAPI(Python) and full-stack web development.</p>"},{"location":"development/#customize-home","title":"Customize Home","text":"<p>This section will cover how to customize the home page.</p> <p>Get Started</p>"},{"location":"development/#add-view","title":"Add View","text":"<p>This section will guide you through the process of adding a new visualization view to the app.</p> <p>Get Started</p>"},{"location":"development/add_view/","title":"Add new visualization views","text":"<p>Follow the steps below to add a new visualization view / page.</p>"},{"location":"development/add_view/#step-1-create-visualization-view-folder-and-file","title":"Step 1: Create visualization view folder and file","text":"<ul> <li>Create a new folder in the <code>frontend/src/pages</code> directory. e.g. <code>frontend/src/pages/DemoView</code></li> <li>Create an index.jsx file in the <code>frontend/src/pages/DemoView</code> directory. e.g. <code>frontend/src/pages/DemoView/index.jsx</code></li> </ul>"},{"location":"development/add_view/#step-2-customize-visualization-view-content","title":"Step 2: Customize visualization view content","text":"<ul> <li>Write the visualization view code in the <code>frontend/src/pages/DemoView/index.jsx</code> file.</li> <li>Your code will looks like this:     <pre><code>import ...;\nfunction DemoView() {\n    return (\n        &lt;div&gt;\n            &lt;h1&gt;Demo View&lt;/h1&gt;\n        &lt;/div&gt;\n    );\n}\n\nexport default DemoView;\n</code></pre><ul> <li>In this page you need to import and use the status storage variables.</li> </ul> </li> </ul>"},{"location":"development/add_view/#step-3-define-status-store-and-api-requests","title":"Step 3: Define status Store and API requests","text":"<ul> <li>Use zustand to create a store and use it in the <code>DemoView</code> component.<ul> <li>To get the data from the backend, you need to create a status Store file in the <code>frontend/src/stores</code> directory. e.g. <code>frontend/src/stores/DemoViewStore.js</code>.</li> <li>Define status variables and actions in the <code>DemoViewStore.js</code> file.</li> <li>Write the data fetching logic in the <code>DemoViewStore.js</code> file (Import and call the API requests functions).</li> <li>Save the data in the status variables.</li> </ul> </li> <li>Define API requests in the <code>frontend/src/api</code> directory. e.g. <code>frontend/src/api/DemoViewApi.js</code>.<ul> <li>Use axios to send API requests to the backend endpoints.</li> <li>e.g.  <pre><code>export const getDemoViewData = async (dataset,query_str) =&gt; {\n    try {\n        const response = await axios.get(`${BACKEND_API_URL}/getdemoviewdata`,\n            {params: {dataset:dataset,query_str:query_str}});\n        return response;\n    } catch (error) {\n        console.error(\"Error in getDemoViewData:\", error);\n        throw error;\n    }\n}\n</code></pre></li> <li>This above function needs to be imported and called in the <code>DemoViewStore.js</code> file.</li> </ul> </li> </ul>"},{"location":"development/add_view/#step-4-backend-routes","title":"Step 4: Backend Routes","text":"<ul> <li>Add backend API routes in the <code>backend/routes</code> directory. e.g. <code>backend/routes/demoview_routes.py</code>.<ul> <li>Write the request handler logics in the <code>backend/routes/demoview_routes.py</code> file.</li> <li>Import and call the processing functions.</li> <li>This file needs to be imported and configured in the FastAPI app in the <code>backend/main.py</code> file.<ul> <li><code>app.include_router(demoview_routes.router, prefix=\"/demoview\")</code></li> </ul> </li> </ul> </li> <li>Add backend processing functions in the <code>backend/funcs</code> directory. e.g. <code>backend/funcs/demo_view.py</code>.<ul> <li>Write the processing functions in the <code>backend/funcs/demo_view.py</code> file.</li> <li>Return the processed data to the request handler.</li> </ul> </li> </ul>"},{"location":"development/add_view/#step-5-test-the-new-visualization-view","title":"Step 5: Test the new visualization view","text":"<ul> <li>Run the project following the instructions in the Install section.</li> <li>Access the new visualization view in the browser.</li> <li>Test the API requests and status storage variables.</li> </ul>"},{"location":"development/customize_home/","title":"Customize a Home Page for Your Project","text":"<p>Follow the steps below to customize the home page which fits your own use case.</p>"},{"location":"development/customize_home/#step-1-create-home-page-folder-and-file","title":"Step 1: Create home page folder and file","text":"<ul> <li>Create a new folder in the <code>frontend/src/pages</code> directory. e.g. <code>frontend/src/pages/DemoHome</code></li> <li>Create an index.jsx file in the <code>frontend/src/pages/DemoHome</code> directory. e.g. <code>frontend/src/pages/DemoHome/index.jsx</code></li> </ul>"},{"location":"development/customize_home/#step-2-customize-home-page-content","title":"Step 2: Customize home page content","text":"<ul> <li>We have provided a default home page in the <code>frontend/src/pages/Home</code> directory. You can copy the content from it and modify it to fit your own use case.</li> <li>At this stage you can  modify the numbers of datasets, samples, and features to fit your own use case.</li> <li>TODO: Automatically obtain the numbers of datasets, samples, and features from the backend is under development.</li> </ul>"},{"location":"development/customize_home/#step-3-configure-the-env-file","title":"Step 3: Configure the .env file","text":"<ul> <li>Modify the content of the <code>fontend/env/.env</code> file to point to your own home page.</li> <li>The content of the <code>fontend/env/.env</code> file should be like this: <pre><code># title\nVITE_APP_TITLE = Demo Project\n\n# home page view options, fill the folder name of the home page here\nVITE_HOME_PAGE = DemoHome\n\n# runnning port, for running locally in development mode\nVITE_PORT = 3000\n</code></pre></li> </ul>"},{"location":"development/customize_home/#step-4-run-the-project","title":"Step 4: Run the project","text":"<ul> <li>Run the project following the instructions in the Install section.</li> </ul>"},{"location":"install/","title":"Install the BrainDataPortal","text":"<p>This document will guide you through the process of installing the BrainDataPortal. Follow the steps to set up your development environment and get BrainDataPortal running locally or in the cloud.</p>"},{"location":"install/#1-prerequisites","title":"1. Prerequisites","text":"<p>Before you begin, ensure you have the following installed on your system:</p> <ul> <li>Python 3.10 or higher: Required to run the backend.</li> <li>Node.js 22 or higher: Required to run the frontend.</li> <li>[Optional] Conda: Set up a virtual environment</li> <li>[Optional] Git: Clone the repository</li> </ul>"},{"location":"install/#2-get-codes","title":"2. Get codes","text":"<ol> <li>Clone the repository.     <pre><code>git clone https://github.com/huruifeng/BrainDataPortal.git\n</code></pre>    Or, download the zipped repository from https://github.com/huruifeng/BrainDataPortal</li> <li>Setup backend environment.<ul> <li>[Optional] Create a virtual environment. <pre><code> conda create -n braindataportal python=3.10 \n conda activate braindataportal\n</code></pre></li> <li>Change to the BrainDataPortal/backend directory.</li> <li>Install dependencies. <pre><code> pip install -r requirements.txt\n</code></pre></li> </ul> </li> </ol>"},{"location":"install/#3-run-the-backend","title":"3. Run the backend.","text":"<p>Important Note</p> <p>Make sure you are in the ROOT directory of the project (e.g., BrainDataPortal) directory, NOT the backend folder</p>"},{"location":"install/#option-1-run-in-the-terminal","title":"Option 1: Run in the terminal.","text":"<pre><code>  uvicorn backend.main:app --host 0.0.0.0 --port 8000 --workers 4 --proxy-headers\n  # The above command will start the backend server on port 8000\n  # The --proxy-headers option is required to enable CORS\n  # The --workers option specifies the number of worker processes\n  # The --host option specifies the host IP address, Default is 127.0.0.1\n  #     0.0.0.0 means listening on all IP addresses.\n  #     Use 127.0.0.1 for listening on localhost.\n  # The --port option specifies the port number, Default is 8000\n  #     This port number is used to access the backend server\n  #     It will be used in the frontend code, or in proxy server setup\n  #     MAKE SURE THE PORT IS NOT BLOCKED.\n\n  # Stop the backend server\n  &lt;Ctrl + C&gt; - Press Ctrl+C in the terminal to stop the backend server\n</code></pre>"},{"location":"install/#option-2-run-in-the-background-using-nohup","title":"Option 2: Run in the background using nohup.","text":"<pre><code>  nohup uvicorn backend.main:app --host 0.0.0.0 --port 8000 --workers 4 --proxy-headers &gt;&gt; backend.log 2&gt;&amp;1 &amp;\n  # The '&gt;&gt; backend.log 2&gt;&amp;1 &amp;' redirects the output to a log file\n  # The &amp; runs the command in the background\n\n  # To stop the backend server, use the following command:\n  kill -9 $(lsof -t -i:8000)\n</code></pre>"},{"location":"install/#4-setup-frontend","title":"4. Setup frontend","text":""},{"location":"install/#41-global-environment","title":"4.1 Global environment","text":"<ul> <li>Set global environment variables in the .env file (frontend/env/.env). <pre><code># variables in the .env file (frontend/env/.env) - Global settings, always loaded\nVITE_APP_TITLE = BrainDataPortal\n\n# home page view options, the folder name of the home page\nVITE_HOME_PAGE = Home_BDP  \n\n# runnning port, for running locally in development mode\n# This port number is used to access the frontend server, it is different from the backend port\nVITE_PORT = 3000 \n</code></pre></li> </ul>"},{"location":"install/#42-run-the-frontend","title":"4.2 Run the frontend","text":""},{"location":"install/#option-a-development-mode","title":"Option A: Development mode","text":"<ul> <li>Set environment variables in the .env.development file (frontend/env/.env.development).   <pre><code># .env.development - Development settings\n# Run the App locally or in the cloud in dev mode\nVITE_BACKEND_URL = http://&lt;backend-running-ip&gt;:8000\n# The &lt;backend-running-ip&gt; is the IP address where the backend server is running\n# If the backend server is running locally, use 127.0.0.1 or localhost\n# The 8000 is the port number where the backend server is running on, adjust it if needed\n</code></pre></li> <li>Run the frontend locally or in the cloud in dev mode.   <pre><code># Navigate to the frontend directory\ncd BrainDataPortal/frontend\n\n# Install dependencies\nnpm install\n\n# ==============================\n# [Option 1] Running the frontend server in terminal:\n# Start development server\nnpm run dev\n# The above command will start the frontend server on port 3000\n# you can access the frontend at http://&lt;frontend-running-ip&gt;:3000\n\n# Stop the frontend server\n&lt;Ctrl + C&gt; - Press Ctrl+C in the terminal to stop the frontend server\n\n# ==============================\n# [Option 2] Running the frontend server in the background:\nnohup npm run dev &gt;&gt; frontend.log 2&gt;&amp;1 &amp;\n\n# To stop the frontend serverrunning in the background, use the following command:\nkill -9 $(lsof -t -i:3000)\n</code></pre></li> <li>Now, you can access the pages at http://frontend-running-ip:3000 or http://localhost:3000</li> </ul>"},{"location":"install/#option-b-production-modewithout-proxy-server","title":"Option B: Production mode(Without proxy server)","text":"<ul> <li>Set environment variables in the .env.production file (frontend/env/.env.production).   <pre><code># .env.production - Production settings\n# Run the App locally or in the cloud in production mode\nVITE_BACKEND_URL = http://&lt;backend-running-ip&gt;:8000\n# The &lt;backend-running-ip&gt; is the IP address where the backend server is running\n# If the backend server is running locally, use 127.0.0.1 or localhost\n# The 8000 is the port number where the backend server is running on, adjust it if needed\n</code></pre></li> <li>Build the frontend pages.   <pre><code># Navigate to the frontend directory\ncd BrainDataPortal/frontend\n\n# Install dependencies\nnpm install\n\n# Build the frontend pages\nnpm run build\n# This command will build the frontend pages in the frontend/dist folder\n</code></pre></li> <li>Deploy the frontend pages (Apache server or Nginx server)   <pre><code># Navigate to the frontend directory\ncd BrainDataPortal/frontend\n\n# Deploy the frontend pages\nsudo cp -r dist/* /var/www/html\n# This command will copy the frontend pages to the Apache server or Nginx server\n# The /var/www/html is the directory where the frontend pages are deployed\n# You may need to adjust the path (/var/www/html) depending on your Apache server or Nginx server configuration.\n# MAKE SURE THE DIRECTORY IS NOT BLOCKED.\n\n# You may create a subdirectory(e.g. /var/www/html/BrainDataPortal) in the root directory.\n# cp -r dist/* /var/www/html/BrainDataPortal.\n</code></pre></li> <li>Now, you can access the pages at http://Apache_Nginx_server_IP</li> </ul>"},{"location":"install/#option-c-production-mode-nginx-server-with-proxy-service","title":"Option C: Production mode (Nginx server with proxy service).","text":"<ul> <li>Set environment variables in the .env.nginx file (frontend/env/.env.nginx).    <pre><code># .env.nginx - Production settings\n# Run the App in the cloud in production mode\nVITE_BACKEND_URL = ''\n# The backend URL is an empty string, we will use the proxy service to proxy the requests to the backend\n</code></pre></li> <li>Build the frontend pages.   <pre><code># Navigate to the frontend directory\ncd BrainDataPortal/frontend\n\n# Install dependencies\nnpm install\n\n# Build the frontend pages\nnpm run build:nginx\n# This command will build the frontend pages in the frontend/dist folder\n</code></pre></li> <li>Setup the proxy service (Nginx server) (Example configuration file bdpvite_nginx):   <pre><code># Create and edit /etc/nginx/conf.d/BrainDataPortal.conf\n\nserver {\n\n    # Make sure THE PORT IS NOT USED!\n    listen 80;\n    server_name localhost;\n\n    # Replace with the actual path to your frontend production folder, e.g., /var/www/html/BrainDataPortal/dist;\n    root &lt;path-to-your-frontend-production-folder&gt; \n    index index.html;\n\n    # frontend pages\n    location / {\n        try_files $uri /index.html;\n    }\n\n    # API requests - proxy to FastAPI\n    location /api/ {\n        proxy_pass http://localhost:8000; # Replace with your FastAPI server address (e.g., http://localhost:8000)\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n\n    # QTL requests - proxy to FastAPI\n    location /qtl/ {\n        proxy_pass http://localhost:8000;\n        proxy_http_version 1.1;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n\n    location /visium/ {\n        proxy_pass http://localhost:8000;\n        proxy_http_version 1.1;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n\n    location /signal/ {\n        proxy_pass http://localhost:8000;\n        proxy_http_version 1.1;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n\n    location /datasetmanage/ {\n        proxy_pass http://localhost:8000;\n        proxy_http_version 1.1;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n    }\n}\n</code></pre></li> <li>Enable the site <pre><code># Check Nginx configuration\nsudo nginx -t\n\n# Reload Nginx\nsudo systemctl reload nginx\n\n# Check Nginx status\nsudo systemctl status nginx\n</code></pre></li> <li>Now, you can access the pages at http://Apache_Nginx_server_IP</li> <li>Disable the site <pre><code># Remove the configuration file\nsudo rm /etc/nginx/conf.d/BrainDataPortal.conf\n\n# Restart Nginx\nsudo systemctl restart nginx\n\n# Check Nginx status\nsudo systemctl status nginx\n</code></pre></li> </ul>"},{"location":"install/#5-example-pages","title":"5. Example pages","text":""},{"location":"install/#home-page","title":"Home Page","text":""},{"location":"install/#single-cell-umap-clustering","title":"Single Cell UMAP clustering","text":""},{"location":"install/#spatial-transcriptomics","title":"Spatial Transcriptomics","text":""},{"location":"prepare_dataset/","title":"Data Preparation Guides","text":"<p>Learn about supported data formats and how to prepare your datasets for visualization in BrainDataPortal. BrainDataPortal is a comprehensive platform for single-cell, spatial transcriptomics, and other omics data visualization and exploration.  This documentation will guide you through the data preparation processes for different data types.</p>"},{"location":"prepare_dataset/#supported-data-modalities","title":"Supported data modalities","text":"<p>This app supports the visualization of the following data assays:</p> <ul> <li>Single-cell RNA-seq: UMAP plots, gene feature plot, cell cluster markers, DEGs in each cluster</li> <li>Single-cell ATAC-seq: sc-eQTL, sc-eQTL, peak signals, GWAS</li> <li>Visium Spatial Transcriptomics: UMAP plots, gene feature plot, spot cluster markers, DEGs in each cluster</li> </ul> <p>scRNAseq dataset scATACseq dataset VisiumST dataset</p>"},{"location":"prepare_dataset/scrnaseq/","title":"Single-Cell Dataset Preparation","text":"<p>Step-by-step guide for preparing single-cell RNA-seq data for visualization in BrainDataPortal.</p> <p>Learn how to prepare and process single-cell/nuclei RNA sequencing data for visualization in BrainDataPortal.  This section covers seurat object processing, gene expression data splitting, metadata table preparation and data formatting.</p> <p>We will use a brain dataset as an example and cover all essential preprocessing steps.</p>"},{"location":"prepare_dataset/scrnaseq/#1-prerequisites","title":"1. Prerequisites","text":"<ul> <li>Python 3.8+ with pandas, numpy, json libraries installed.</li> <li>R 4.0+ with Seurat, tidyverse, presto packages installed.</li> <li>Basic understanding of single-cell RNA-seq concepts.</li> </ul>"},{"location":"prepare_dataset/scrnaseq/#2-download-demo-data","title":"2. Download demo data","text":"<p>We will use a single-cell dataset from human brain.  This dataset contains 10 subjects, approximately 50,000 cells from brain middle temporal gyrus region.</p> <ul> <li>Demo dataset and scripts: <ol> <li>Seurat object: snRNAseq_MTG_10samples.rds</li> <li>Sample metadata sheet: Sample_snRNAseq_MTG_10samples.csv</li> <li>Dataset configuration file: dataset_info.toml</li> <li>Processing script: sc_script.zip</li> </ol> </li> </ul>"},{"location":"prepare_dataset/scrnaseq/#3-data-loading-and-checking","title":"3. Data loading and checking","text":"<p>Once you have the data, Load it and perform initial inspection to understand the dataset structure.</p> <p>Full code in Notebook: 11.extract_SC_v4.R.</p> <p>You need to pay attention to the input arguments: seurat_obj_file, output_dir, cluster_col</p> <pre><code>## Rscript 11.extract_SC_v4.R\n... ...\n# Get the arguments\nseurat_obj_file &lt;- \"snRNAseq_MTG_10samples.rds\"\noutput_dir &lt;- \"snRNAseq_MTG_10samples\"\ncluster_col &lt;- \"MajorCellTypes\"\n\n# Load the Seurat object\nseurat_obj &lt;- readRDS(seurat_obj_file)\ncapture.output(str(seurat_obj), file = paste0(output_dir, \"/seurat_obj_structure.txt\"))\n... ...\n</code></pre> <p>Important Note</p> <p>The above code will generate a file named seurat_obj_structure.txt in the output directory.  Check this file to see the structure of the Seurat object, Make sure the necessary data is present.</p> <p> Required data in Seurat object</p> <pre><code>sc RNAseq Seurat RDS/\n|-- @assays                     ## List of assays\n|   |-- RNA                     ## RNA data\n|   |   |-- @counts             ## Raw counts\n|   |   |-- @data               ## Normalized data\n|   |   |-- @features           ## Feature/Gene names, v5 format\n|   |   `-- @cells              ## Cell names/ID, v5 format, \n|   `-- ...\n|-- @meta.data                  ## Cell level Metadata table\n|   |-- cell_id                 ## Cell ID\n|   |-- cell_type               ## Cell type annotation\n|   |-- sample_id               ## Sample ID\n|   |-- nCount_RNA              ## Number of UMI counts in the cell\n|   |-- nFeature_RNA            ## Number of genes detected in the cell\n|   `-- ...\n|-- @reductions                 ## Dimensionality reduction results\n|   |--umap                \n|   |   |-- @cell.embeddings    ## UMAP coordinates for each cell\n|   |   `-- ...\n|   `-- ...\n`-- ...\n</code></pre>"},{"location":"prepare_dataset/scrnaseq/#4-data-extraction","title":"4. Data extraction","text":"<p>After check the structure of the Seurat object, we can extract the data and metadata from the object.</p> <p>Full code in Notebook: 11.extract_SC_v4.R.</p> <p>Important Note</p> <p>Seurat v5 has a different structure compared to v4, you may need to adjust the following codes accordingly.</p>  v4 Seurat Object <pre><code>## 1. Extract the normalized counts\nnormalized_counts &lt;- seurat_obj@assays$RNA@data  # This is a sparse matrix\n\n## 2. Convert sparse matrix to triplet format (long format)\nlong_data &lt;- summary(normalized_counts)\n\n## 3. Get row (gene) and column (cell) names\nlong_data$Gene &lt;- rownames(normalized_counts)[long_data$i]\nlong_data$Cell &lt;- colnames(normalized_counts)[long_data$j]\nlong_data$Expression &lt;- long_data$x\n\n## 4. Keep only necessary columns\nlong_data &lt;- long_data[, c(\"Gene\", \"Cell\", \"Expression\")]\n</code></pre> v5 Seurat Object <pre><code>## 1. Extract normalized data\nnorm_data &lt;- seurat_obj[[\"RNA\"]]@layers[[\"data\"]]   # This is a sparse matrix\n\n## 2. Get gene and cell names from LogMaps\ngene_names &lt;- dimnames(seurat_obj[[\"RNA\"]]@features)[[1]]\ncell_names &lt;- dimnames(seurat_obj[[\"RNA\"]]@cells)[[1]]\n\n## 3. Convert to triplet format (sparse matrix summary)\ntriplet &lt;- summary(norm_data)\n\n## 4. Map i and j indices to gene and cell names\ntriplet$Gene &lt;- gene_names[triplet$i]\ntriplet$Cell &lt;- cell_names[triplet$j]\n\n## 5. Reorder and rename\nlong_data &lt;- triplet %&gt;% select(Cell, Gene, Expression = x)\n</code></pre>"},{"location":"prepare_dataset/scrnaseq/#5-metadata-processing","title":"5. Metadata processing","text":"<p>This step processes single cell metadata for visualization, including:</p> <ul> <li>Metadata filtering and renaming</li> <li>UMAP embedding sampling (Subset UMAP points for faster loading)</li> <li>Expression data splitting and saving (Save gene expression data in json files)</li> <li>Pseudo-bulk level expression calculation</li> </ul> <p>Full code in Notebook: 21.rename_meta.py.</p> <p>Set the following parameters according to your dataset: <pre><code>## This is the output directory from the previous step \ndataset_path = \"snRNAseq_MTG_10samples\"  \n\n## a list of metadata columns to keep, pick features that you want to visualize\nkept_features =[ \"nCount_RNA\", \"nFeature_RNA\", \"sex\", \"MajorCellTypes\", \n                \"updrs\", \"Complex_Assignment\", \"mmse\", \"sample_id\", \"case\",]\nsample_col = \"sample_id\"\ncluster_col = \"MajorCellTypes\"\ncondition_col = \"case\"\n</code></pre></p>"},{"location":"prepare_dataset/scrnaseq/#6-computing-cluster-markers","title":"6. Computing cluster markers","text":"<p>This step computes cluster markers for each cluster, including:</p> <ul> <li>Finding cell cluster specific markers</li> <li>Calculating differential expression between conditions within each cell cluster</li> <li>Performing pseudo-bulk analysis</li> </ul> <p>Full code in Notebook: 31.clustermarkers.R.</p> <p>Set the following parameters according to your dataset: <pre><code>## Dataset specific parameters\nseurat_obj_file &lt;- \"snRNAseq_MTG_10samples.rds\"\noutput_dir &lt;- \"snRNAseq_MTG_10samples\"\ncluster_col &lt;- \"MajorCellTypes\"\ncondition_col &lt;- \"case\"\nsample_col &lt;- \"sample_id\"\nseurat_type &lt;- \"snrnaseq\"\n</code></pre></p> <p>Important Note</p> <p>You may need to adjust the following codes for your specific dataset. <pre><code>if (!\"data\" %in% slotNames(seurat_obj@assays$RNA)) {\n    stop(\"The Seurat object does not contain the 'data' slot in the 'RNA' assay.\")\n}\n... ...\n# Check if the Seurat object has the necessary assay\nif (!\"ATAC\" %in% names(seurat_obj@assays)) {\n    stop(\"The Seurat object does not contain the 'ATAC' assay.\")\n}\n# Check if the Seurat object has the necessary assay data\nif (!\"counts\" %in% slotNames(seurat_obj@assays$ATAC)) {\n    stop(\"The Seurat object does not contain the 'counts' slot in the 'ATAC' assay.\")\n}\n... ...\n# Check if the Seurat object has the necessary assay\nif (!\"Spatial\" %in% names(seurat_obj@assays)) {\n    stop(\"The Seurat object does not contain the 'Spatial' assay.\")\n}\n# Check if the Seurat object has the necessary assay data\nif (!\"data\" %in% slotNames(seurat_obj@assays$Spatial)) {\n    stop(\"The Seurat object does not contain the 'data' slot in the 'Spatial' assay.\")\n}\n</code></pre></p>"},{"location":"prepare_dataset/scrnaseq/#7-post-marker-processing","title":"7. Post-marker processing","text":"<p>This step identifies and analyzes top marker genes for each cell type (or cluster) from single-cell data. It also calculates detection frequency and average expression for selected marker genes across conditions and sexes.</p> <p>Full code in Notebook: 41_clustermarkers_postprocess.py.</p> <p>Modify the following codes for your specific dataset. <pre><code># Define dataset and metadata column names\ndataset_folder = \"example_data/snRNA_MTG_10Samples\"\ncluster_col = \"MajorCellTypes\"\nsex_col = \"sex\"\noutput_folder = dataset_folder + \"/clustermarkers\"\n... ...\n\n# Filter for significant genes\nfiltered_df = marker_genes[marker_genes['p_val_adj'] &lt; 0.05]\n\n# Rank by absolute log2FC and select top 10 per cluster\ntop_genes = (\n    filtered_df\n    .assign(abs_log2FC = filtered_df['avg_log2FC'])  ## chenge to abs(filtered_df['avg_log2FC']) will include negative log2FC genes\n    .sort_values(['cluster', 'abs_log2FC'], ascending=[True, False])\n    .groupby('cluster')\n    .head(10)\n    .drop(columns='abs_log2FC')  # Optional: remove helper column\n)\n... ...\n</code></pre></p>"},{"location":"prepare_dataset/scrnaseq/#8-prepare-sample-sheet","title":"8. Prepare sample sheet","text":"<p>This step generates a sample sheet file for the dataset. It includes information about the samples, such as condition, sex, and other relevant metadata.</p> <p>Download the demo sample sheet file: Sample_snRNAseq_MTG_10samples.csv</p> <p>Important Note</p> <p>PLEASE KEEP ALL THE COLUMN NAMES AND ORDER AS IS, JUST FILL IN YOUR DATA.</p>"},{"location":"prepare_dataset/scrnaseq/#9-dataset-configuration-file","title":"9. Dataset configuration file","text":"<p>This step prepares the dataset information.</p> <ul> <li>The dataset information file is a toml file.</li> <li>It is an essential file for the dataset.</li> </ul> <p>Download the demo dataset information file: dataset_info.toml</p> <p>Important Note</p> <p>Dataset configuration file name must be dataset_info.toml.</p> <p>Here is an example of the dataset configuration file content: <pre><code>[datasetfile]\nfile = \"\"                               ## Path to the Seurat object file\ndatatype = \"\"                           ## Type of the data. Options: scRNAseq, scATACseq, VisiumST, xQTL\n\n[dataset]\ndataset_name = \"\"                       ## Required: Dataset name, MUST BE UNIQUE, used to identify the dataset in the database\ndescription = \"\"                        ## Dataset description\nPI_full_name = \"\"                       ## Principal Investigator (PI) full name\nPI_email = \"\"                           ## PI email\nfirst_contributor = \"\"                  ## First contributor name\nfirst_contributor_email = \"\"            ## First contributor email\nother_contributors = \"\"                 ## Other contributors\nsupport_grants = \"\"                     ## Support grants\nother_funding_source = \"\"               ## Other funding source\npublication_DOI = \"\"                    ## DOI of the publication\npublication_PMID = \"\"                   ## PMID of the publication\nbrain_super_region = \"\"                 ## Brain super region\nbrain_region = \"\"                       ## Brain region\nsample_info = \"\"                        ## Sample information\nsample_sheet = \"\"                       ## Sample sheet file name (Not the path, just the file name)\nn_samples = 96                          ## Number of samples\norganism = \"Homo Sapiens\"               ## Organism\ntissue = \"Brain\"                        ## Tissue\ndisease = \"PD\"                          ## Disease\n\n[study]\nstudy_name = \"Parkinson5D\"              ## Study name, the dataset belongs to\ndescription = \"\"                        ## Study description\nteam_name = \"Team Scherzer\"             ## Team name\nlab_name = \"NeuroGenomics\"              ## Lab name\nsubmitter_name = \"\"                     ## Submitter name\nsubmitter_email = \"\"                    ## Submitter email\n\n[protocol]\nprotocol_id = \"P002\"                    ## Protocol ID\nprotocol_name = \"P001_VisiumST\"         ## Protocol name\nversion = \"\"                            ## Protocol version\ngithub_url = \"\"                         ## GitHub URL\nsample_collection_summary = \"\"          ## Sample collection summary\ncell_extraction_summary = \"\"            ## Cell extraction summary\nlib_prep_summary = \"\"                   ## Library preparation summary\ndata_processing_summary = \"\"            ## Data processing summary\nprotocols_io_DOI = \"\"                   ## protocols.io DOI\nother_reference = \"\"                    ## Other reference\n\n[meta_features]\nselected_features = [\"nCount_Spatial\",...] ## List of selected features will be shown in the page\nsample_id_column = \"sample_name\"        ## Sample ID column in Seurat object metadata\nmajor_cluster_column = \"CellType\"       ## Major cluster column in Seurat object metadata\ncondition_column = \"diagnosis\"          ## Condition column in Seurat object metadata        \n\n[visium_defaults]\nsamples = [ \"BN2023\", \"BN1076\",]         ## List of sample names\nfeatures = [ \"smoothed_label_s5\",...]    ## List of default feature names\ngenes = [ \"SNCA\",...]                    ## List of default gene names\n</code></pre></p>"},{"location":"prepare_dataset/scrnaseq/#10-upload-dataset","title":"10. Upload dataset","text":"<p>Upload the dataset to server folder.</p> <p>After running the pipeline, there will be a dataset folder that contains all necessary files:</p> <ul> <li>The files with names starting with raw_ are NOT necessary for upload.</li> <li>The file named 'pb_expr_matrix.csv' in the folder '&lt;dataset_name&gt;/clustermarkers' is NOT necessary for upload.</li> <li>Upload the dataset folder named '&lt;dataset_name&gt;' to the server at 'backend/datasets'.</li> <li>Put the dataset configuration file named 'dataset_info.toml' to your dataset folder at 'backend/datasets/&lt;dataset_name&gt;'.</li> <li>Upload samplesheet file to the server at 'backend/SampleSheet'.</li> <li>Refresh the database: Go to 'Datasets Management Page '(DATASETS -&gt; +ADD DATASET) and click 'REFRESH DB'.</li> </ul>"},{"location":"prepare_dataset/visiumst/","title":"Visium ST Dataset Preparation","text":"<p>Step-by-step guide for preparing Visium ST RNA-seq data for visualization in BrainDataPortal.</p> <p>Learn how to prepare and process Visium ST data for visualization in BrainDataPortal.  This section covers seurat object processing, gene expression data splitting, metadata table preparation and data formatting.</p> <p>We will use a brain dataset as an example and cover all essential preprocessing steps.</p>"},{"location":"prepare_dataset/visiumst/#1-prerequisites","title":"1. Prerequisites","text":"<ul> <li>Python 3.8+ with pandas, numpy, json libraries installed.</li> <li>R 4.0+ with Seurat, tidyverse, presto packages installed.</li> <li>Basic understanding of Visium ST concepts.</li> </ul>"},{"location":"prepare_dataset/visiumst/#2-download-demo-data","title":"2. Download demo data","text":"<p>We will use a Visium ST dataset from human brain.  This dataset contains 10 subjects, approximately 40,000 spots from brain middle temporal gyrus region.</p> <ul> <li>Demo dataset and scripts: <ol> <li>Seurat object: VisiumST_MTG_10samples.rds</li> <li>Sample metadata sheet: Sample_VisiumST_MTG_10samples.csv</li> <li>Dataset configuration file: dataset_info.toml</li> <li>Processing script: visiumst_script.zip</li> </ol> </li> </ul>"},{"location":"prepare_dataset/visiumst/#3-data-loading-and-checking","title":"3. Data loading and checking","text":"<p>Once you have the data, Load it and perform initial inspection to understand the dataset structure.</p> <p>Full code in Notebook: 11.extract_VisiumST.R.</p> <p>You need to pay attention to the input arguments: seurat_obj_file, output_dir, cluster_col</p> <pre><code>## Rscript 11.extract_SC_v4.R\n... ...\n# Get the arguments\nseurat_obj_file &lt;- \"Visium_MTG_10samples.rds\"\noutput_dir &lt;- \"Visium_MTG_10samples\"\ncluster_col &lt;- \"smoothed_label_s5\"\n\n# Load the Seurat object\nseurat_obj &lt;- readRDS(seurat_obj_file)\ncapture.output(str(seurat_obj), file = paste0(output_dir, \"/seurat_obj_structure.txt\"))\n... ...\n</code></pre> <p>Important Note</p> <p>The above code will generate a file named seurat_obj_structure.txt in the output directory.  Check this file to see the structure of the Seurat object, Make sure the necessary data is present.</p> <p> Required data in Seurat object</p> <pre><code>sc RNAseq Seurat RDS/\n|-- @assays                     ## List of assays\n|   |-- Spatial                 ## RNA data\n|   |   |-- @counts             ## Raw counts\n|   |   |-- @data               ## Normalized data\n|   |   |-- @features           ## Feature/Gene names, v5 format\n|   |   `-- @cells              ## Cell names/ID, v5 format, \n|   `-- ...\n|-- @meta.data                  ## Cell level Metadata table\n|   |-- cell_id                 ## Cell ID\n|   |-- cell_type               ## Cell type annotation\n|   |-- sample_id               ## Sample ID\n|   |-- nCount_RNA              ## Number of UMI counts in the cell\n|   |-- nFeature_RNA            ## Number of genes detected in the cell\n|   `-- ...\n|-- @reductions                 ## Dimensionality reduction results\n|   |--umap                \n|   |   |-- @cell.embeddings    ## UMAP coordinates for each cell\n|   |   `-- ...\n|   `-- ...\n|-- @images                     ## Spatial image data\n|   |-- Sample1                 ## Image name\n|   |   |-- @image              ## Image data\n|   |   |-- @coordinates        ## Image coordinates\n|   |   `-- @scale.factors      ## Image scale\n|   |-- Sample2                 ## Image name\n|   |   |-- ...\n|   `-- ...\n`-- ...\n</code></pre>"},{"location":"prepare_dataset/visiumst/#4-data-extraction","title":"4. Data extraction","text":"<p>After check the structure of the Seurat object, we can extract the data and metadata from the object.</p> <p>Full code in Notebook: 11.extract_VisiumST.R.</p> <p>Important Note</p> <p>Seurat v5 has a different structure compared to v4, you may need to adjust the following codes accordingly.</p>  v4 Seurat Object <pre><code>## 1. Extract the normalized counts\nnormalized_counts &lt;- seurat_obj@assays$RNA@data  # This is a sparse matrix\n\n## 2. Convert sparse matrix to triplet format (long format)\nlong_data &lt;- summary(normalized_counts)\n\n## 3. Get row (gene) and column (cell) names\nlong_data$Gene &lt;- rownames(normalized_counts)[long_data$i]\nlong_data$Cell &lt;- colnames(normalized_counts)[long_data$j]\nlong_data$Expression &lt;- long_data$x\n\n## 4. Keep only necessary columns\nlong_data &lt;- long_data[, c(\"Gene\", \"Cell\", \"Expression\")]\n</code></pre> v5 Seurat Object <pre><code>## 1. Extract normalized data\nnorm_data &lt;- seurat_obj[[\"RNA\"]]@layers[[\"data\"]]   # This is a sparse matrix\n\n## 2. Get gene and cell names from LogMaps\ngene_names &lt;- dimnames(seurat_obj[[\"RNA\"]]@features)[[1]]\ncell_names &lt;- dimnames(seurat_obj[[\"RNA\"]]@cells)[[1]]\n\n## 3. Convert to triplet format (sparse matrix summary)\ntriplet &lt;- summary(norm_data)\n\n## 4. Map i and j indices to gene and cell names\ntriplet$Gene &lt;- gene_names[triplet$i]\ntriplet$Cell &lt;- cell_names[triplet$j]\n\n## 5. Reorder and rename\nlong_data &lt;- triplet %&gt;% select(Cell, Gene, Expression = x)\n</code></pre>"},{"location":"prepare_dataset/visiumst/#5-metadata-processing","title":"5. Metadata processing","text":"<p>This step processes single cell metadata for visualization, including:</p> <ul> <li>Metadata filtering and renaming</li> <li>UMAP embedding sampling (Subset UMAP points for faster loading)</li> <li>Expression data splitting and saving (Save gene expression data in json files)</li> <li>Pseudo-bulk level expression calculation</li> </ul> <p>Full code in Notebook: 21.rename_meta.py.</p> <p>Set the following parameters according to your dataset: <pre><code>## This is the output directory from the previous step \ndataset_path = \"Visium_MTG_10samples\" \n\n## a list of metadata columns to keep, pick features that you want to visualize\nkept_features =[\"nCount_Spatial\",\"nFeature_Spatial\",\"sample_name\",\"sex\",\"diagnosis\",\n                \"last_mmse_test_score\",\"motor_updrs_score\",\"smoothed_label_s5\"]\nsample_col = \"sample_name\"\ncluster_col = \"smoothed_label_s5\"\ncondition_col = \"diagnosis\"\n</code></pre></p>"},{"location":"prepare_dataset/visiumst/#6-computing-cluster-markers","title":"6. Computing cluster markers","text":"<p>This step computes cluster markers for each cluster, including:</p> <ul> <li>Finding cluster specific markers</li> <li>Calculating differential expression between conditions within each cluster</li> <li>Performing pseudo-bulk analysis</li> </ul> <p>Full code in Notebook: 31.clustermarkers.R.</p> <p>Set the following parameters according to your dataset: <pre><code>## Dataset specific parameters\nseurat_obj_file &lt;- \"Visium_MTG_10samples\"\noutput_dir &lt;- \"datasets/Visium_MTG_10samples\"\ncluster_col &lt;- \"smoothed_label_s5\"\ncondition_col &lt;- \"diagnosis\"\nsample_col &lt;- \"sample_name\"\nseurat_type &lt;- \"visiumst\" # options: \"scrnaseq\", \"snrnaseq\", \"snatacseq\", \"scatacseq\", \"visiumst\"\n</code></pre></p> <p>Important Note</p> <p>You may need to adjust the following codes for your specific dataset. <pre><code>if (!\"data\" %in% slotNames(seurat_obj@assays$RNA)) {\n    stop(\"The Seurat object does not contain the 'data' slot in the 'RNA' assay.\")\n}\n... ...\n# Check if the Seurat object has the necessary assay\nif (!\"ATAC\" %in% names(seurat_obj@assays)) {\n    stop(\"The Seurat object does not contain the 'ATAC' assay.\")\n}\n# Check if the Seurat object has the necessary assay data\nif (!\"counts\" %in% slotNames(seurat_obj@assays$ATAC)) {\n    stop(\"The Seurat object does not contain the 'counts' slot in the 'ATAC' assay.\")\n}\n... ...\n# Check if the Seurat object has the necessary assay\nif (!\"Spatial\" %in% names(seurat_obj@assays)) {\n    stop(\"The Seurat object does not contain the 'Spatial' assay.\")\n}\n# Check if the Seurat object has the necessary assay data\nif (!\"data\" %in% slotNames(seurat_obj@assays$Spatial)) {\n    stop(\"The Seurat object does not contain the 'data' slot in the 'Spatial' assay.\")\n}\n</code></pre></p>"},{"location":"prepare_dataset/visiumst/#7-post-marker-processing","title":"7. Post-marker processing","text":"<p>This step identifies and analyzes top marker genes for each cell type (or cluster) from Visium ST data. It also calculates detection frequency and average expression for selected marker genes across conditions and sexes.</p> <p>Full code in Notebook: 41_clustermarkers_postprocess.py.</p> <p>Modify the following codes for your specific dataset. <pre><code># Define dataset and metadata column names\ndataset_folder = \"example_data/snRNA_MTG_10Samples\"\ncluster_col = \"MajorCellTypes\"\nsex_col = \"sex\"\noutput_folder = dataset_folder + \"/clustermarkers\"\n... ...\n\n# Filter for significant genes\nfiltered_df = marker_genes[marker_genes['p_val_adj'] &lt; 0.05]\n\n# Rank by absolute log2FC and select top 10 per cluster\ntop_genes = (\n    filtered_df\n    .assign(abs_log2FC = filtered_df['avg_log2FC'])  ## chenge to abs(filtered_df['avg_log2FC']) will include negative log2FC genes\n    .sort_values(['cluster', 'abs_log2FC'], ascending=[True, False])\n    .groupby('cluster')\n    .head(10)\n    .drop(columns='abs_log2FC')  # Optional: remove helper column\n)\n... ...\n</code></pre></p>"},{"location":"prepare_dataset/visiumst/#8-prepare-sample-sheet","title":"8. Prepare sample sheet","text":"<p>This step generates a sample sheet file for the dataset. It includes information about the samples, such as condition, sex, and other relevant metadata.</p> <p>Download the demo sample sheet file: Sample_VisiumST_MTG_10samples.csv</p> <p>Important Note</p> <p>PLEASE KEEP ALL THE COLUMN NAMES AND ORDER AS IS, JUST FILL IN YOUR DATA.</p>"},{"location":"prepare_dataset/visiumst/#9-dataset-configuration-file","title":"9. Dataset configuration file","text":"<p>This step prepares the dataset information.</p> <ul> <li>The dataset information file is a toml file.</li> <li>It is an essential file for the dataset.</li> </ul> <p>Download the demo dataset information file: dataset_info.toml</p> <p>Important Note</p> <p>Dataset configuration file name must be dataset_info.toml.</p> <p>Here is an example of the dataset configuration file content: <pre><code>[datasetfile]\nfile = \"\"                               ## Path to the Seurat object file\ndatatype = \"\"                           ## Type of the data. Options: scRNAseq, scATACseq, VisiumST, xQTL\n\n[dataset]\ndataset_name = \"\"                       ## Required: Dataset name, MUST BE UNIQUE, used to identify the dataset in the database\ndescription = \"\"                        ## Dataset description\nPI_full_name = \"\"                       ## Principal Investigator (PI) full name\nPI_email = \"\"                           ## PI email\nfirst_contributor = \"\"                  ## First contributor name\nfirst_contributor_email = \"\"            ## First contributor email\nother_contributors = \"\"                 ## Other contributors\nsupport_grants = \"\"                     ## Support grants\nother_funding_source = \"\"               ## Other funding source\npublication_DOI = \"\"                    ## DOI of the publication\npublication_PMID = \"\"                   ## PMID of the publication\nbrain_super_region = \"\"                 ## Brain super region\nbrain_region = \"\"                       ## Brain region\nsample_info = \"\"                        ## Sample information\nsample_sheet = \"\"                       ## Sample sheet file name (Not the path, just the file name)\nn_samples = 96                          ## Number of samples\norganism = \"Homo Sapiens\"               ## Organism\ntissue = \"Brain\"                        ## Tissue\ndisease = \"PD\"                          ## Disease\n\n[study]\nstudy_name = \"Parkinson5D\"              ## Study name, the dataset belongs to\ndescription = \"\"                        ## Study description\nteam_name = \"Team Scherzer\"             ## Team name\nlab_name = \"NeuroGenomics\"              ## Lab name\nsubmitter_name = \"\"                     ## Submitter name\nsubmitter_email = \"\"                    ## Submitter email\n\n[protocol]\nprotocol_id = \"P002\"                    ## Protocol ID\nprotocol_name = \"P001_VisiumST\"         ## Protocol name\nversion = \"\"                            ## Protocol version\ngithub_url = \"\"                         ## GitHub URL\nsample_collection_summary = \"\"          ## Sample collection summary\ncell_extraction_summary = \"\"            ## Cell extraction summary\nlib_prep_summary = \"\"                   ## Library preparation summary\ndata_processing_summary = \"\"            ## Data processing summary\nprotocols_io_DOI = \"\"                   ## protocols.io DOI\nother_reference = \"\"                    ## Other reference\n\n[meta_features]\nselected_features = [\"nCount_Spatial\",...] ## List of selected features will be shown in the page\nsample_id_column = \"sample_name\"        ## Sample ID column in Seurat object metadata\nmajor_cluster_column = \"CellType\"       ## Major cluster column in Seurat object metadata\ncondition_column = \"diagnosis\"          ## Condition column in Seurat object metadata        \n\n[visium_defaults]\nsamples = [ \"BN2023\", \"BN1076\",]         ## List of sample names\nfeatures = [ \"smoothed_label_s5\",...]    ## List of default feature names\ngenes = [ \"SNCA\",...]                    ## List of default gene names\n</code></pre></p>"},{"location":"prepare_dataset/visiumst/#10-upload-dataset","title":"10. Upload dataset","text":"<p>Upload the dataset to server folder.</p> <p>After running the pipeline, there will be a dataset folder that contains all necessary files:</p> <ul> <li>The files with names starting with raw_ are NOT necessary for upload.</li> <li>The file named 'pb_expr_matrix.csv' in the folder '&lt;dataset_name&gt;/clustermarkers' is NOT necessary for upload.</li> <li>Upload the dataset folder named '&lt;dataset_name&gt;' to the server at 'backend/datasets'.</li> <li>Put the dataset configuration file named 'dataset_info.toml' to your dataset folder at 'backend/datasets/&lt;dataset_name&gt;'.</li> <li>Upload samplesheet file to the server at 'backend/SampleSheet'.</li> <li>Refresh the database: Go to 'Datasets Management Page '(DATASETS -&gt; +ADD DATASET) and click 'REFRESH DB'.</li> </ul>"},{"location":"prepare_dataset/xqtl/","title":"xQTL Dataset Preparation","text":"<p>Step-by-step guide for preparing single-cell ATAC-seq/xQTL/GWAS data for visualization in BrainDataPortal.</p> <p>Learn how to prepare and process single-cell/nuclei ATAC-seq/xQTL/GWAS data for visualization in BrainDataPortal.  This section covers seurat object processing, gene expression data splitting, metadata table preparation and data formatting.</p> <p>We will use a brain dataset as an example and cover all essential preprocessing steps.</p>"},{"location":"prepare_dataset/xqtl/#1-prerequisites","title":"1. Prerequisites","text":"<ul> <li>Python 3.8+ with pandas, numpy, json, polars, fastparquet, pyBigWig libraries installed.</li> <li>Basic understanding of single-cell ATAC-seq/QTL concepts.</li> </ul>"},{"location":"prepare_dataset/xqtl/#2-download-demo-data","title":"2. Download demo data","text":"<p>We will use a single-cell dataset from human brain.  This demo dataset contains several cell types from human brain middle brain region.</p> <ul> <li>Demo dataset and scripts: <ol> <li>Seurat object: xQTL_Demo.zip</li> <li>Gene location file: gene_annotations.tsv</li> <li>SNP location file: snp_annotations.tsv</li> <li>GWAS summary file: PD_GWAS.tab</li> <li>Dataset configuration file: dataset_info.toml</li> <li>Processing script: xqtl_script.zip</li> </ol> </li> </ul>"},{"location":"prepare_dataset/xqtl/#3-preprocessing","title":"3. Preprocessing","text":"<p>In this step, we will read the raw xQTL summary files and extract the necessary columns and filter the data based on the p-values.</p> <ul> <li>This script should vary depending on the input data.</li> <li>Renames QTL data columns to `gene_id, snp_id, p_value, beta_value'.</li> <li>Splits QTL data by celltype into <code>unfiltered_celltypes/</code>.</li> <li>Renames gene and SNP annotation columns to <code>gene_id</code>,<code>position_start</code>, <code>position_end</code>, <code>strand</code> and <code>snp_id</code>, <code>position</code>.</li> <li>Filters each celltype in <code>unfiltered_celltypes/</code> for entries with p &gt; 0.01 and outputs filtered TSVs into <code>filtered_celltypes/</code>.</li> </ul> <p>Full code in Python: 01_preprocessing.py.</p> <p>Modify the following parameters according to your dataset and run the script: <pre><code>... ...\n############################\n## define parameters, modify as needed\ndataset_name = \"eQTLsummary_demo\"\nqtl_data_files = sorted(glob(\"eQTLsummary_sampled/*_sampled.tsv\"))\ngeneid_col = \"gene_id\"\nsnpid_col = \"variant_id\"\npvalue_col = \"pval_nominal\"\nbeta_col = \"slope\"\n... ...\n</code></pre></p> <p>Important Note</p> <p>The QTL summary files should be in the TSV format with the following columns:</p> <p> Example xQTL file format (For each cell type,e.g. Astrocytes_eQTL.tsv):</p> <pre><code>Gene    SNP p-value beta\nA1BG    rs1234567   0.02    0.213\nA1BG    rs1234568   0.03    0.314\nA1BG    rs1234569   0.01    0.615\n</code></pre>"},{"location":"prepare_dataset/xqtl/#4-mapping-cell-type-names-to-files","title":"4. Mapping cell type names to files","text":"<p>In this step, we will map the cell type names to the files.  It prompts user for display names that correspond to filenames in<code>celltypes/</code>.  Otherwise the file names will be used.</p> <p>The python script is: 02_celltype_mapping.py.</p> <p>Important Note</p> <p>Change the dataset_name = \"your_dataset_name\" to your dataset name. </p>"},{"location":"prepare_dataset/xqtl/#5global-significance-filtering","title":"5.Global significance filtering","text":"<p>This step identifies gene-SNP pairs significant in at least one celltype using <code>filtered_celltypes/</code>. Filters <code>unfiltered_celltypes/</code> accordingly, and outputs filtered TSVs into <code>celltypes/</code>.</p> <p>Full code in Python: 03_significant.py.</p>"},{"location":"prepare_dataset/xqtl/#6-generate-annotation-jsons","title":"6. Generate annotation JSONs","text":"<p>This step generates annotation JSONs for genes and SNPs. The script reads the <code>gene_annotations.tsv</code> and <code>snp_annotations.tsv</code> files and splits gene and SNP annotation files by chromosome into <code>gene_locations/</code> and <code>snp_locations/</code></p> <p>Full code in Python: 04_annotate.py.</p> <p>Set the following parameters according to your dataset: <pre><code>## Dataset specific parameters\n## define parameters, modify as needed\ndataset_name = \"eQTLsummary_demo\"\ngene_annotation_file = \"data/gene_annotations.tsv\"\ngeneid_col = \"gene_id\"\ngene_start_col = \"position_start\"\ngene_end_col = \"position_end\"\ngene_chrom_col = \"chromosome\" \ngene_strand_col = \"strand\"  \n\nsnp_annotation_file = \"data/snp_annotations.tsv\"\nsnpid_col = \"snp_id\"\nsnp_chrom_col = \"chr\"\nsnp_pos_col = \"position\"\n</code></pre></p> <p>Important Note</p> <p>You can use the demo annotation files provided in the demo data. Or you can prepare your own annotation files.  The annotation files should be in the TSV format with the following columns:</p> <p> Gene annotation file format (TSV)</p> <pre><code>gene    chromosome  start   end strand\nA1BG    1   1234567 1234568 -\nA1BG    1   1234568 1234569 -\nA1BG    1   1234569 1234570 -\n</code></pre> <p> SNP annotation file format (TSV)</p> <pre><code>SNP chromosome  position\nrs1234567   1   1234567\nrs1234568   1   1234568\nrs1234569   1   1234569\n</code></pre>"},{"location":"prepare_dataset/xqtl/#7-convert-to-parquet","title":"7. Convert to Parquet","text":"<p>This step converts all necessary TSV files to Parquet format for final use.</p> <p>Full code: 05_parquet.py.</p> <p>Modify the following codes for your specific dataset. <pre><code># Define dataset name\ndataset_name = \"eQTLsummary_demo\"\n... ...\n</code></pre></p>"},{"location":"prepare_dataset/xqtl/#8-clean-up-unnecessary-files","title":"8. Clean up unnecessary files","text":"<p>This step cleans up unnecessary files. It removes the <code>unfiltered_celltypes/</code> directory and the <code>filtered_celltypes/</code> directory.</p> <p>Full code: 06_filter_clean.py.</p> <p>Modify the following codes for your specific dataset. <pre><code># Define dataset name\ndataset_name = \"eQTLsummary_demo\"\n... ...\n</code></pre></p>"},{"location":"prepare_dataset/xqtl/#9-prepare-gwas-data-for-visualization","title":"9. Prepare GWAS data for visualization","text":"<p>BrainDataPortal can visualize GWAS summary data in the form of a scatter plot. We provided a script to split the GWAS summary data to required TSV format files.</p> <p>Full code: 07_gwas.py.</p> <p>Modify the following codes for your specific dataset. <pre><code>## Dataset specific parameters\ndataset_name = \"eQTLsummary_demo\"\ninput_file = \"PD_GWAS_with_rsIDs_hg38.tab\"\ngwas_chrom_col = \"#chrom\"\ngwas_pos_col = \"chromEnd\"\ngwas_snp_col = \"rsID\"\ngwas_beta_col = \"b\"\ngwas_pval_col = \"p\"\n... ...\n</code></pre></p>"},{"location":"prepare_dataset/xqtl/#10-prepare-dataset-information-file","title":"10. Prepare dataset information file","text":"<p>Download and modify the demo dataset information file: dataset_info.toml</p> <p>Important Note</p> <p>Dataset configuration file name must be dataset_info.toml.</p> <p>Here is an example of the dataset configuration file content: <pre><code>[datasetfile]\nfile = \"\"                               ## Path to the Seurat object file\ndatatype = \"\"                           ## Type of the data. Options: scRNAseq, scATACseq, VisiumST, xQTL\n\n[dataset]\ndataset_name = \"\"                       ## Required: Dataset name, MUST BE UNIQUE, used to identify the dataset in the database\ndescription = \"\"                        ## Dataset description\nPI_full_name = \"\"                       ## Principal Investigator (PI) full name\nPI_email = \"\"                           ## PI email\nfirst_contributor = \"\"                  ## First contributor name\nfirst_contributor_email = \"\"            ## First contributor email\nother_contributors = \"\"                 ## Other contributors\nsupport_grants = \"\"                     ## Support grants\nother_funding_source = \"\"               ## Other funding source\npublication_DOI = \"\"                    ## DOI of the publication\npublication_PMID = \"\"                   ## PMID of the publication\nbrain_super_region = \"\"                 ## Brain super region\nbrain_region = \"\"                       ## Brain region\nsample_info = \"\"                        ## Sample information\nsample_sheet = \"\"                       ## Sample sheet file name (Not the path, just the file name)\nn_samples = 96                          ## Number of samples\norganism = \"Homo Sapiens\"               ## Organism\ntissue = \"Brain\"                        ## Tissue\ndisease = \"PD\"                          ## Disease\n\n[study]\nstudy_name = \"Parkinson5D\"              ## Study name, the dataset belongs to\ndescription = \"\"                        ## Study description\nteam_name = \"Team Scherzer\"             ## Team name\nlab_name = \"NeuroGenomics\"              ## Lab name\nsubmitter_name = \"\"                     ## Submitter name\nsubmitter_email = \"\"                    ## Submitter email\n\n[protocol]\nprotocol_id = \"P002\"                    ## Protocol ID\nprotocol_name = \"P001_VisiumST\"         ## Protocol name\nversion = \"\"                            ## Protocol version\ngithub_url = \"\"                         ## GitHub URL\nsample_collection_summary = \"\"          ## Sample collection summary\ncell_extraction_summary = \"\"            ## Cell extraction summary\nlib_prep_summary = \"\"                   ## Library preparation summary\ndata_processing_summary = \"\"            ## Data processing summary\nprotocols_io_DOI = \"\"                   ## protocols.io DOI\nother_reference = \"\"                    ## Other reference\n\n[meta_features]\nselected_features = [\"nCount_Spatial\",...] ## List of selected features will be shown in the page\nsample_id_column = \"sample_name\"        ## Sample ID column in Seurat object metadata\nmajor_cluster_column = \"CellType\"       ## Major cluster column in Seurat object metadata\ncondition_column = \"diagnosis\"          ## Condition column in Seurat object metadata        \n\n[visium_defaults]\nsamples = [ \"BN2023\", \"BN1076\",]         ## List of sample names\nfeatures = [ \"smoothed_label_s5\",...]    ## List of default feature names\ngenes = [ \"SNCA\",...]                    ## List of default gene names\n</code></pre></p>"},{"location":"prepare_dataset/xqtl/#11-upload-dataset","title":"11. Upload dataset","text":"<p>Upload the dataset to server folder.</p> <p>After running the pipeline, there will be a dataset folder that contains all necessary files:</p> <ul> <li>The files and folders within the <code>your_dataset_name</code> folder are necessary for upload.</li> <li>Upload the dataset folder named '&lt;dataset_name&gt;' to the server at 'backend/datasets'.</li> <li>Put the dataset configuration file named 'dataset_info.toml' to your dataset folder at 'backend/datasets/&lt;dataset_name&gt;'.</li> <li>Refresh the database: Go to 'Datasets Management Page '(DATASETS -&gt; +ADD DATASET) and click 'REFRESH DB'.</li> </ul>"}]}